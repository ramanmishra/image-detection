{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.layers import flatten\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"product.pickle\"\n",
    "\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    \n",
    "X_train,y_train = train['images'],train['labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15def9e0208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NORMALIZATION##\n",
    "\n",
    "def normalize_data(data):\n",
    "    data_norm = (data - data.mean()) / (np.max(data) - np.min(data))\n",
    "    return data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray(X_train_image):\n",
    "    return cv2.cvtColor(X_train_image,cv2.COLOR_RGB2BGRA)\n",
    "\n",
    "for i in X_train:\n",
    "    gray(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productClassifier(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x16.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 16), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(16))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # : Activation and dropout\n",
    "    conv1=tf.nn.dropout(tf.nn.relu(conv1), keep_prob)\n",
    "\n",
    "    # : Pooling. Input = 28x28x16. Output = 14x14x16.\n",
    "    #conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    conv1= tf.nn.dropout(tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID'), keep_prob)\n",
    "    \n",
    "    \n",
    "    # : Layer 2: Convolutional. Output = 10x10x32.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 32), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(32))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # : Activation.and dropout\n",
    "    \n",
    "    conv2=tf.nn.dropout(tf.nn.relu(conv2), keep_prob)\n",
    "    \n",
    "    # : Pooling. Input = 10x10x32. Output = 5x5x32.\n",
    "    #conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    conv2 = tf.nn.dropout(tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID'), keep_prob)\n",
    "    \n",
    "    # : Flatten. Input = 5x5x32. Output = 800.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # : Layer 3: Fully Connected. Input = 800. Output = 240.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(800, 240), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(240))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # : Activation and dropout\n",
    "    #fc1    = tf.nn.relu(fc1)\n",
    "    fc1    =tf.nn.dropout(tf.nn.relu(fc1), keep_prob)\n",
    "\n",
    "    # : Layer 4: Fully Connected. Input = 240. Output = 140.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(240, 140), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(140))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    \n",
    "\n",
    "    # : Activation and dropout\n",
    "    #fc2    = tf.nn.relu(fc2)\n",
    "    fc2    = tf.nn.dropout(tf.nn.relu(fc2), keep_prob)\n",
    "\n",
    "    # : Layer 5: Fully Connected. Input = 140. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(140, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "##TRAINING PIPELINE\n",
    "rate = 0.001\n",
    "\n",
    "logits = productClassifier(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    total_loss=0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy,loss = sess.run([accuracy_operation,loss_operation], feed_dict={x: batch_x, y: batch_y,keep_prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "        total_loss += (loss * len(batch_x))\n",
    "    return total_accuracy / num_examples, total_loss / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 225, 225, 3) for Tensor 'Placeholder_12:0', which has shape '(?, 32, 32, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-3b58483b71b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_operation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#validation_accuracy = evaluate(X_valid, y_valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1101\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 225, 225, 3) for Tensor 'Placeholder_12:0', which has shape '(?, 32, 32, 1)'"
     ]
    }
   ],
   "source": [
    "\n",
    "###TRAINING THE MODEL...\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    loss_history = {\"train\":[],\"valid\":[]}\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y,keep_prob:0.8})\n",
    "            \n",
    "        #validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        (validation_accuracy, validation_loss) = evaluate(X_valid, y_valid)\n",
    "        (training_accuracy, training_loss) = evaluate(X_train, y_train)\n",
    "        loss_history[\"valid\"].append(validation_loss)\n",
    "        loss_history[\"train\"].append(training_loss)\n",
    "        \n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
